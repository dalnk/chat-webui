# chat-webui
focusing on the LLaMA/Alpaca/Vicuna model but hopefully expanding to other models soon. Thank you to @geohot for making tinygrad and @ggerganov for llama.cpp

Alpaca now runs on android!

Ideally supporting Vicu√±a and StableLM. Theres a working version using webgpu here: https://mlc.ai/web-llm/
