# chat-ui
focusing on the LLaMA/Alpaca/Vicuna/Koala/Dolly model but hopefully expanding to other models soon. Thank you to @geohot for making tinygrad and pytorch for ONNX conversions. Need to use quantized files like q4-ggml-vicuna

Alpaca now runs on android! Vicuna and StableLM work now as well
Using huggingface chat for this as well
Whisper.cpp for voice to text

Ideally supporting Vicu√±a and StableLM. Theres a working version using webgpu here: https://mlc.ai/web-llm/
